---
title: "Towards Efficient and Reliable Generative and Sampling Models"
author: "Tianshu Yu"
date: 2025-11-07
categories: ["McGill Statistics Seminar"]
tags: ["2025 Fall"]
---

#### Date: 2025-11-07
#### Time: 15:30-16:30 (Montreal time)
#### Location: In person, Burnside 1104
#### [https://mcgill.zoom.us/j/87181846336](https://mcgill.zoom.us/j/87181846336)
#### Meeting ID: 871 8184 6336
#### Passcode: None



## Abstract:

This talk presents a unified framework for enhancing the reliability and geometric fidelity of generative models. We first develop a diffusion mechanism defined intrinsically on the SE(3) manifold, enabling the efficient sampling. To address the critical issue of mode collapse in energy-based samplers, we introduce a novel Importance Weighted Score Matching method that provably improves coverage of complex, multi-modal distributions. Finally, we extend these principles to infer underlying dynamical systems directly from incomplete and scattered training data. Collectively, this work bridges geometric consistency, statistical reliability, and learning from partial observations to advance the frontiers of generative and sampling models.

## Speaker

Tianshu Yu is currently an assistant professor at School of Data Science, The Chinese University of Hong Kong, Shenzhen (CUHK-Shenzhen). He leads Learning Of Graph & Optimization Lab (LOGO Lab) and is now a visiting assistant professor at MILA - Quebec AI Institute. Tianshu serves as the Co-Editor-in-Chief of Science Digitalization (AIMS Publishing). His research interest generally covers Machine Learning for Optimization (ML4Opt) and AI4Science, with a particular forcus of bringing together machine learning and PDEs.